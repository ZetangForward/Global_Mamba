model_name_or_path: "mamba-1.4b"
tokenizer_name_or_path: "mamba-1.4b-hf"
ckpt_path: "/nvme/hf_models/mamba-1.4b/pytorch_model.bin"
load_model_state_dict: False
use_relative_position: False
use_abs_position: False
use_custom_module: True
max_position_embeddings: 16384