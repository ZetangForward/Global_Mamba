platform: &platform "h800"
mark: &mark pretrain
state: &state "train"
exp_task: &exp_task "slimpajama"
model_name: &model_name "mamba_370m_big_kernel"

defaults:
  - _self_
  - platform: *platform
  - task: *exp_task
  - model: *model_name

hydra:
  job:
    name: ${exp_task}
  run:
    dir: ./runs/${exp_task}-${model_name}/version_${mark}/${hydra.job.name}

optimizer:
  optimizer_type: "adamw"
  lr: 3e-4
  beta_1: 0.9
  beta_2: 0.95
  num_training_steps: 13500
  warmup_steps: 1350
  peak_lr: 3e-4
  last_lr: 1e-5

lr_scheduler:
  scheduler_type: "get_cosine_schedule_with_warmup"
  warmup_steps: 0

experiment:
  seed: 27
  model_save_dir: ${exp_task}-${model_name}
  save_top_k: 2
  monitor_metric: "train_lm_loss"
  accumulate_grad_batches: 1
  use_deepspeed: True
  debug: False
  hf_trainer: False
  low_rank_train: False
  device_num: 1
  node_num: 1